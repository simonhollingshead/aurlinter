#!/bin/bash

source config

prep() {
	if [ ! -d ./res/sourced ]; then
		bsdtar -C ./res -xzf ./res/sourceall.tar.gz
	fi
}

coalesce() {
	if [[ -f res/goodurls ]]; then
		comm -23 <(sort res/urllist) <(sort res/goodurls) | sponge res/urllist
		rm res/goodurls
	fi
}

urlcheck() {
	cat res/urllist | parallel -N 50 -j50 '
	UA="Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0"
	HOSTPATH='"$HOSTPATH"'

	fetch_http() {
		# First, try a standard HEAD request.  2xx is a good reply, malformed URL or failed DNS resolve immediately halt.
		QUERY1=$(curl -sIkLA "$UA" -m 15 -o /dev/null -w %{http_code} -- "$1")
		ERRCODE=$?
		{ [[ "$QUERY1" -ge 200 ]] && [[ "$QUERY1" -lt 300 ]]; } && return 0
		{ [[ "$ERRCODE" -eq 3 ]] || [[ "$ERRCODE" -eq 6 ]]; } && return 1

		# Second chance, for those that block HEAD.  Use GET, but with a partial request for the first byte only.  2xx good.
		QUERY2=$(curl -skLA "$UA" -m 15 -o /dev/null --header "Range: bytes=0-1" -w %{http_code} -- "$1")
		ERRCODE=$?
		{ [[ "$QUERY2" -ge 200 ]] && [[ "$QUERY2" -lt 300 ]]; } && return 0

		# Last chance!  Make curl use GET, but internally think it asked for HEAD.  Stops it fetching actual content.
		QUERY3=$(curl -skLIA "$UA" -X GET -m 15 -o /dev/null -w %{http_code} -- "$1")
		{ [[ "$QUERY3" -ge 200 ]] && [[ "$QUERY3" -lt 300 ]]; } && return 0

		# We tried our very best.
		return 1
	}

	fetch_ftp() {
		[[ $(curl -sLIm 15 -o /dev/null -w %{http_code} -- "$1") == 350 ]]
		return $?
	}

	fetch_git() {
		case "$2" in
			"tag")
				./3.2-expect "$1" "$HOSTPATH/3.1-gitwrap" "refs/tags/$3" &>/dev/null
				;;
			"branch")
				./3.2-expect "$1" "$HOSTPATH/3.1-gitwrap" "refs/heads/$3" &>/dev/null
				;;
			"commit"|"")
				# FIXME: You cannot query remote for a given SHA... but who would make up a whole giant hash?
				./3.2-expect "$1" "$HOSTPATH/3.1-gitwrap" &>/dev/null
				;;
			*)
				false
				;;
		esac
		return $?
	}

	fetch_svn() {
		case "$2" in
			"revision")
				svn info -r "$3" -- "$1" &>/dev/null
				;;
			"")
				svn info -- "$1" &>/dev/null
				;;
			*)
				false
				;;
		esac
		return $?
	}

	fetch_bzr() {
		bzr revno -- "$1" &>/dev/null
		return $?
	}

	fetch_hg() {
		case "$2" in
			"branch"|"revision"|"tag")
				hg id -r "$3" -- "$1" &>/dev/null
				;;
			"")
				hg id -r tip -- "$1" &>/dev/null
				;;
			*)
				false
				;;
		esac
		return $?
	}

	fetch_rsync() {
		rsync --list-only -- "$1" &>/dev/null
		return $?
	}

	URLS=( {} )
	for URL in "${URLS[@]}"
	do
		URLMINUSHINT="${URL#*+}"
		PROTOCOL="${URL%%://*}"
		HINT="${PROTOCOL%%+*}"
		VCSSELECTOR=${URL##*#}
		VCSSELECTORNAME=${VCSSELECTOR%%=*}
		VCSSELECTORVAL=${VCSSELECTOR#*=}
		
		if [[ "$URL" != "" ]]; then
			case "$PROTOCOL" in
				"http"|"https")
					fetch_http "$URL" && echo "$URL"
					;;
				"ftp")
					fetch_ftp "$URL" && echo "$URL"
					;;
				"git")
					fetch_git "${URL%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
					;;
				"svn")
					fetch_svn "${URL%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
					;;
				"bzr")
					fetch_bzr "${URL%%#*}" && echo "$URL"
					;;
				"hg")
					fetch_hg "${URL%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
					;;
				"rsync")
					fetch_rsync "$URL" && echo "$URL"
					;;
				"scp")
					# TODO
					;;
				"file")
					echo "$URL"
					;;
				*)
					case "$HINT" in
						"git")
							fetch_git "${URLMINUSHINT%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
							;;
						"svn")
							fetch_svn "${URLMINUSHINT%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
							;;
						"bzr")
							fetch_bzr "${URLMINUSHINT%%#*}" && echo "$URL"
							;;
						"hg")
							fetch_hg "${URLMINUSHINT%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
							;;
						*)
							echo "$URL" >&2
							;;
					esac
					;;
			esac
		fi
	done
	' > res/goodurls
}

# prep
# coalesce
# urlcheck
# coalesce
# urlcheck
# coalesce