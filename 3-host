#!/bin/bash

source config

prep() {
	if [[ ! -d ./res/sourced ]]; then
		bsdtar -C ./res -xzf ./res/sourceall.tar.gz
	fi
}

coalesce() {
	if [[ -f res/goodurls ]]; then
		comm -23 <(sort res/urllist) <(sort res/goodurls) | sponge res/urllist
		rm res/goodurls
	fi
}

urlcheck() {
	SHELL=/usr/bin/bash parallel -N 50 -j50 '
	UA="Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0"
	HOSTPATH='"$HOSTPATH"'

	fetch_http() {
		# FIXME: All of the QUERYx for HTTP use the -k flag since people could install their own certs.
		# FIXME continued: If there was some policy that people cannot be expected to install new certs, they can be removed.
		# First, try a standard HEAD request.  Malformed URL or failed DNS resolve immediately halt.
		QUERY1=$(curl -sIkLA "$UA" -m 15 -o /dev/null -w %{http_code} -- "$1")
		ERRCODE=$?
		[[ "$QUERY1" == "200" ]] && return 0
		[[ "$ERRCODE" -eq 3 ]] && echo "http: Malformed URL $@." >&2 && return 1
		[[ "$ERRCODE" -eq 6 ]] && echo "http: DNS lookup failed for $@." >&2 && return 1

		# Second chance, for those that block HEAD.  Use GET, but with a partial request for the first byte only.
		# 206 is expected, but some that follow spec badly still give 200 OK.
		QUERY2=$(curl -skLA "$UA" -m 15 -o /dev/null --header "Range: bytes=0-1" -w %{http_code} -- "$1")
		{ [[ "$QUERY2" == "206" ]] || [[ "$QUERY2" == "200" ]]; } && return 0

		# Last chance!  Make curl use GET, but internally think it asked for HEAD.  Stops it fetching actual content.
		QUERY3=$(curl -sIkLA "$UA" -X GET -m 15 -o /dev/null -w %{http_code} -- "$1")
		{ [[ "$QUERY3" == "206" ]] || [[ "$QUERY3" == "200" ]]; } && return 0

		# We tried our very best.
		[[ "$QUERY3" == "000" ]] && echo "http: Connection to $@ timed out." >&2 && return 1
		echo "http: HTTP $QUERY3 returned for $@." >&2 && return 1
	}

	fetch_ftp() {
		QUERY1=$(curl -sLIm 15 -o /dev/null -w %{http_code} -- "$1")
		ERRCODE=$?
		[[ "$QUERY1" == 350 ]] && return 0
		[[ "$ERRCODE" -eq 3 ]] && echo "ftp: Malformed URL $@." >&2 && return 1
		[[ "$ERRCODE" -eq 6 ]] && echo "ftp: DNS lookup failed for $@." >&2 && return 1
		[[ "$QUERY1" == "000" ]] && echo "ftp: Connection to $@ timed out." >&2 && return 1
		echo "ftp: FTP $QUERY1 returned for $@." >&2 && return 1
	}

	fetch_git() {
		case "$2" in
			"tag")
				./3.2-expect "$1" "$HOSTPATH/3.1-gitwrap" "refs/tags/$3" &>/dev/null && return 0
				;;
			"branch")
				./3.2-expect "$1" "$HOSTPATH/3.1-gitwrap" "refs/heads/$3" &>/dev/null && return 0
				;;
			"commit"|"")
				# FIXME: You cannot query remote for a given SHA... but who would make up a whole giant hash?
				./3.2-expect "$1" "$HOSTPATH/3.1-gitwrap" &>/dev/null && return 0
				;;
			*)
				false
				;;
		esac

		RETURNVAL=$?
		case "$RETURNVAL" in
			"1")
				echo "git: Unrecognised selector fragment in $@." >&2
				;;
			"2")
				echo "git: Remote repository no longer contains the requested fragment for $@." >&2
				;;
			"99")
				echo "git: Connection forcibly timed out to $@." >&2
				;;
			"128")
				echo "git: Could not connect to $@." >&2
				;;
			*)
				echo "git: Unexpected error ($RETURNVAL) requesting $@." >&2
				;;
		esac
		return 1
	}

	fetch_svn() {
		case "$2" in
			"revision")
				RETURNVAL=$(svn info -r "$3" -- "$1" 2>&1)
				[[ $? == 0 ]] && return 0
				RETURNVAL=$(echo "$RETURNVAL" | grep -o "E[0-9]*" | tail -1)
				;;
			"")
				RETURNVAL=$(svn info -- "$1" 2>&1)
				[[ $? == 0 ]] && return 0
				RETURNVAL=$(echo "$RETURNVAL" | grep -o "E[0-9]*" | tail -1)
				;;
			*)
				false
				;;
		esac

		case "$RETURNVAL" in
			"1")
				echo "svn: Unrecognised selector fragment in $@." >&2
				;;
			"E000110")
				echo "svn: No repository found at $@." >&2
				;;
			"E160006")
				echo "svn: No such revision found for $@." >&2
				;;
			"E200009")
	 			echo "svn: Remote repository no longer contains the requested fragment for $@." >&2
	 			;;
	 		*)
	 			echo "svn: Unexpected error ($RETURNVAL) requesting $@." >&2
	 			;;
	 	esac
		return 1
	}

	fetch_bzr() {
		bzr revno -- "$1" &>/dev/null && return 0
		RETURNVAL=$?
		case "$RETURNVAL" in
			"3")
 				echo "bzr: No repository found at $@." >&2
 				;;
	 		*)
	 			echo "bzr: Unexpected error ($RETURNVAL) requesting $@." >&2
	 			;;
	 	esac
		return 1
	}

	fetch_hg() {
		case "$2" in
			"branch"|"revision"|"tag")
				RETURNVAL=$(hg id -r "$3" -- "$1" 2>&1)
				[[ $? == 0 ]] && return 0
				RETURNVAL=$(echo "$RETURNVAL" | grep "^abort: ")
				;;
			"")
				RETURNVAL=$(hg id -r tip -- "$1" 2>&1)
				[[ $? == 0 ]] && return 0
				RETURNVAL=$(echo "$RETURNVAL" | grep "^abort: ")
				;;
			*)
				RETURNVAL="Unrecognised selector fragment."
				;;
		esac
		echo "hg: Failed fetching $@: $RETURNVAL" >&2
		return 1
	}

	fetch_rsync() {
		rsync --list-only -- "$1" &>/dev/null && return 0
		RETURNVAL=$?
		case "$RETURNVAL" in
			"5")
				echo "rsync: No files found at $@." >&2
				;;
			"10")
				echo "rsync: Could not connect to the server at $@." >&2
				;;
	 		*)
	 			echo "rsync: Unexpected error ($RETURNVAL) requesting $@." >&2
	 			;;
	 	esac
		return 1
	}

	URLS=( {} )
	for URL in "${URLS[@]}"
	do
		URLMINUSHINT="${URL#*+}"
		PROTOCOL="${URL%%://*}"
		HINT="${PROTOCOL%%+*}"
		VCSSELECTOR=${URL##*#}
		VCSSELECTORNAME=${VCSSELECTOR%%=*}
		VCSSELECTORVAL=${VCSSELECTOR#*=}
		[[ "$URL" == "$VCSSELECTOR" ]] && unset VCSSELECTORNAME && unset VCSSELECTORVAL
		
		if [[ "$URL" != "" ]]; then
			case "$PROTOCOL" in
			 	"http"|"https")
			 		fetch_http "$URL" && echo "$URL"
			 		;;
			 	"ftp")
			 		fetch_ftp "$URL" &&	echo "$URL"
			 		;;
			 	"git")
			 		fetch_git "${URL%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
			 		;;
			 	"svn")
					fetch_svn "${URL%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
					;;
			 	"bzr")
					fetch_bzr "${URL%%#*}" && echo "$URL"
			 		;;
			 	"hg")
			 		fetch_hg "${URL%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
			 		;;
			 	"rsync")
					fetch_rsync "$URL" && echo "$URL"
			 		;;
			 	"scp")
			 		# TODO
			 		;;
			 	*)
			 		case "$HINT" in
			 			"git")
			 				fetch_git "${URLMINUSHINT%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
			 				;;
			 			"svn")
			 				fetch_svn "${URLMINUSHINT%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
			 				;;
			 			"bzr")
			 				fetch_bzr "${URLMINUSHINT%%#*}" && echo "$URL"
			 				;;
			 			"hg")
			 				fetch_hg "${URLMINUSHINT%%#*}" "$VCSSELECTORNAME" "$VCSSELECTORVAL" && echo "$URL"
			 				;;
			 			*)
			 				echo "???: Unrecognised protocol, checking failed for $URL." >&2
			 				;;
			 		esac
			 		;;
			esac
		fi
	done
	' :::: ./res/urllist >res/goodurls 2>res/faillog
}

genreport() {
	cat <<REPORTHEADER
Each package was sourced in a container with only base and base-devel, with a read-only working directory and no network connection.  This is intentional, since the act of sourcing should not be writing files, downloading files, or using anything that cannot be checked against the dependency array by makepkg first.

REPORTHEADER

	echo "==========================================================[Extraction]"
	if [[ "$VERBOSITY" -ge 5 ]]; then
		cat res/extractbugs
	elif [[ "$VERBOSITY" -ge 3 ]]; then
		grep "^E: \|^W: " "./res/extractbugs" | sed 's/:$//'
	else
		grep "^E: " "./res/extractbugs" | sed 's/:$//'
	fi

	if [[ "$VERBOSITY" -ge 3 ]]; then
		echo
		echo "========================================[Extracted folder permissions]"
		if [[ "$VERBOSITY" -ge 5 ]]; then
			cat res/permissionbugs
		else
			sed 's|.*/||' "./res/permissionbugs"
		fi
	fi

	echo
	echo "=====================================[PKGBUILDs unable to be analysed]"
	pushd ./res/temporary >/dev/null
	if [[ "$VERBOSITY" -ge 3 ]]; then
		for j in $(
			for i in *
			do
				[[ -e "$i" ]] || continue
				echo "${i%-*}"
			done | uniq)
		do
			echo "$j:"
			for k in "$j-"*
			do
				[[ -e "$k" ]] || continue
				[[ -s "$k" ]] && tail -v "$k"
			done
			echo
		done
	else
		for i in *
		do
			[[ -e "$i" ]] || continue
			echo "${i%-*}"
		done | uniq 
	fi
	popd >/dev/null

	echo
	echo "=================================================[Main package faults]"
	pushd ./res/sourced/ >/dev/null
	VALIDARCHES=(any x86_64 i686 arm armv6h armv7h) # Order these with most popular first, since inarray ends early in such cases.
	VALIDOPTIONS=(strip docs libtool staticlibs emptydirs zipman purge upx debug ccache distcc buildflags makeflags)
	VALIDILICENSES=(AGPL AGPL3 Artistic2.0 CCPL CDDL CPL EPL FDL FDL1.2 FDL1.3 GPL GPL2 GPL3 LGPL LGPL2.1 LGPL3 LPPL MPL PerlArtistic PHP PSF RUBY W3C ZPL zsync BSD MIT Python zlib/libpng)
	VALIDLICENSES=(Apache APACHE)
	# End of array markers below for iteration assistance.
	ALLPKGFIELDS=(pkgdesc pkgname pkgrel pkgver url '-') # REQUIRED STRINGS (pkgname is a special case in the event of split packages)
	ALLPKGFIELDS+=(arch license '--') # REQUIRED ARRAYS
	ALLPKGFIELDS+=(changelog epoch install pkgbase pkgdir srcdir startdir '---') # OTHER STRINGS
	ALLPKGFIELDS+=(backup checkdepends conflicts depends groups makedepends md5sums noextract optdepends options provides replaces sha1sums sha256sums sha384sums sha512sums source) # OTHER ARRAYS
	[[ "$VERBOSITY" -ge 3 ]] && BASEANDDEVEL=$(expac -Sg '%n' base base-devel | SHELL=/usr/bin/bash parallel -j8 'pactree -sl {}' | awk '{print $1;}' | awk 'BEGIN{RS=ORS="\n"}!a[$0]++' | SHELL=/usr/bin/bash parallel -j8 'echo {}; expac -S1 "%S" {} | sed "s/  /\n/g" | grep -v "\.so$"' | awk 'BEGIN{RS=ORS="\n"}!a[$0]++')
	# Regular expressions below with a character count have to be written {number\} otherwise parallel understands it as the {n} option.  \{\} is interpreted as \{} instead.
	find . -type f | sort | SHELL=/usr/bin/bash parallel -k -N 50 -j8 '
		inarray() { local insensitive=$1 n=$2 h; shift 2; $insensitive && shopt -s nocasematch; for h; do [[ $n = "$h" ]] || continue; $insensitive && shopt -u nocasematch; return 0; done; shopt -u nocasematch; return 1; }
		validate_pkgname() { [[ "$ROVERBOSITY" -ge 4 ]] && [[ "$pkgname" != "$ROEXTRACTEDDIRNAME" ]] && [[ "$pkgbase" != "$ROEXTRACTEDDIRNAME" ]] && echo "[*] Unzipped directory name and pkgname do not match.  ($ROEXTRACTEDDIRNAME =/= $pkgname)"; }
		validate_pkgver() { [[ "$pkgrel" =~ [^A-Za-z0-9._] ]] && echo "[*] Disallowed pkgver format.  ($pkgver)"; }
		validate_pkgrel() { [[ "$ROVERBOSITY" -ge 3 ]] && [[ "$pkgrel" =~ [^0-9] ]] && echo "[*] Non-integer or negative pkgrel.  ($pkgrel)"; }
		validate_pkgdesc() { [[ "$ROVERBOSITY" -ge 3 ]] && local COMPAREWITH=$(if [[ "$pkgbase" != "" ]]; then echo "$pkgbase"; else echo "$pkgname"; fi); grep -qwf <(echo "$pkgname") <(echo "$COMPAREWITH") && echo "[*] Found package name inside pkgdesc. ($COMPAREWITH)"; { { [[ "$ROVERBOSITY" == 3 ]] && [[ ${#pkgdesc} -gt 150 ]]; } || { [[ "$ROVERBOSITY" == 4 ]] && [[ ${#pkgdesc} -gt 100 ]]; } || { [[ "$ROVERBOSITY" -ge 5 ]] && [[ ${#pkgdesc} -gt 70 ]]; } } && echo "[*] Pkgdesc is excessively long. (${#pkgdesc} chars)"; }
		validate_url() { grep -qxFf <(echo "$url" | sed "\|://|!d;s|/$||") "../urllist" && echo "[*] Could not connect to address in url field.  ($url)"; }
		validate_arch() { [[ "$ROVERBOSITY" -ge 2 ]] && local ARCHITECTURENAME && for ARCHITECTURENAME in "${arch[@]}"; do inarray false "$ARCHITECTURENAME" "${ROVALIDARCHES[@]}" || echo "[*] Architecture not recognised.  ($ARCHITECTURENAME)"; done; }
		validate_license() { [[ "$ROVERBOSITY" -ge 4 ]] && local LICENSENAME && for LICENSENAME in "${license[@]}"; do [[ "$LICENSENAME" == "custom" ]] || { [[ "$LICENSENAME" == "custom:"?* ]] && { ! inarray true "${LICENSENAME#custom:}" "${ROVALIDILICENSES[@]}" && ! inarray false "${LICENSENAME#custom:}" "${ROVALIDLICENSES[@]}"; }; } || inarray true "$LICENSENAME" "${ROVALIDILICENSES[@]}" || inarray false "$LICENSENAME" "${ROVALIDLICENSES[@]}" || echo "[*] Bad license name.  ($LICENSENAME)"; done; }
		validate_pkgdir() { [[ "$pkgdir" != "" ]] && echo "[*] Sets pkgdir.  (To $pkgdir)"; }
		validate_srcdir() { [[ "$srcdir" != "" ]] && echo "[*] Sets srcdir.  (To $srcdir)"; }
		validate_startdir() { [[ "$startdir" != "" ]] && echo "[*] Sets startdir.  (To $startdir)"; }
		validate_epoch() { [[ "$ROVERBOSITY" -ge 3 ]] && [[ "$epoch" =~ [^0-9] ]] && echo "[*] Non-integer or negative epoch.  ($epoch)"; }
		validate_pkgbase() { return; }
		validate_groups() { [[ "$ROVERBOSITY" -ge 5 ]] && [[ $(IFS=""; echo "${groups}[@]") != "" ]] && echo "[*] AUR packages gain no benefit from having a defined group."; }
		validate_install() { [[ $install != "" ]] && [ ! -f "../../prep/ext/$ROEXTRACTEDDIRNAME/$install" ] && echo "[*] Install file not found in archive.  ($install)"; }
		validate_changelog() { return; }
		validate_depends() { return; }
		validate_optdepends() { return; }
		validate_makedepends() { return; }
		validate_checkdepends() { return; }
		validate_provides() { return; }
		validate_conflicts() { return; }
		validate_replaces() { return; }
		validate_backup() { return; }
		validate_options() { [[ "$ROVERBOSITY" -ge 3 ]] && local OPTIONNAME && for OPTIONNAME in "${options[@]}"; do { [[ $OPTIONNAME == "" ]] || inarray false "${OPTIONNAME#!}" "${ROVALIDOPTIONS[@]}"; } || echo "[*] Unknown option.  ($OPTIONNAME)"; done; }
		validate_source() { local COMPARETO=$(IFS=$'"'\n'"'; grep -Fxf <(echo "${source[*]}" | sed "\|://|!d;s/::/\n/;s/^.*\n//;s|/$||") "../urllist"); [[ "$COMPARETO" != "" ]] && echo "[*] Could not connect to the following sources:" && echo "$COMPARETO"; }
		validate_noextract() { return; }
		validate_md5sums() { [[ "${#md5sums[@]}" != 0 ]] && NUMSUMTYPES=$((NUMSUMTYPES + 1)) && local MD5SUM && for MD5SUM in "${md5sums[@]}"; do { [[ "$MD5SUM" == "SKIP" ]] || [[ "$MD5SUM" =~ ^[0-9a-f]{32\}$ ]]; } && NUMSUMS=$((NUMSUMS + 1)) || echo "Malformed md5sum.  ($MD5SUM)"; done; }
		validate_sha1sums() { [[ "${#sha1sums[@]}" != 0 ]] && NUMSUMTYPES=$((NUMSUMTYPES + 1)) && local SHA1SUM && for SHA1SUM in "${sha1sums[@]}"; do { [[ "$SHA1SUM" == "SKIP" ]] || [[ "$SHA1SUM" =~ ^[0-9a-f]{40\}$ ]]; } && NUMSUMS=$((NUMSUMS + 1)) || echo "Malformed sha1sum.  ($SHA1SUM)"; done; }
		validate_sha256sums() { [[ "${#sha256sums[@]}" != 0 ]] && NUMSUMTYPES=$((NUMSUMTYPES + 1)) && local SHA256SUM && for SHA256SUM in "${sha256sums[@]}"; do { [[ "$SHA256SUM" == "SKIP" ]] || [[ "$SHA256SUM" =~ ^[0-9a-f]{64\}$ ]]; } && NUMSUMS=$((NUMSUMS + 1)) || echo "Malformed sha256sum.  ($SHA256SUM)"; done; }
		validate_sha384sums() { [[ "${#sha384sums[@]}" != 0 ]] && NUMSUMTYPES=$((NUMSUMTYPES + 1)) && local SHA384SUM && for SHA384SUM in "${sha384sums[@]}"; do { [[ "$SHA384SUM" == "SKIP" ]] || [[ "$SHA384SUM" =~ ^[0-9a-f]{96\}$ ]]; } && NUMSUMS=$((NUMSUMS + 1)) || echo "Malformed sha384sum.  ($SHA384SUM)"; done; }
		validate_sha512sums() { [[ "${#sha512sums[@]}" != 0 ]] && NUMSUMTYPES=$((NUMSUMTYPES + 1)) && local SHA512SUM && for SHA512SUM in "${sha512sums[@]}"; do { [[ "$SHA512SUM" == "SKIP" ]] || [[ "$SHA512SUM" =~ ^[0-9a-f]{128\}$ ]]; } && NUMSUMS=$((NUMSUMS + 1)) || echo "Malformed sha512sum.  ($SHA512SUM)"; done; }
		validate_archivefiles() { return; }
		validate_disgustingstrings() { return; } # sudo, || return 1... all that stuff.

		INPUT=( {} )
		for PACKAGE in "${INPUT[@]}"
		do
			EXTRACTEDDIRNAME="${PACKAGE##*/}"
			APPLICABLEARCHES="${EXTRACTEDDIRNAME##*-}"
			EXTRACTEDDIRNAME="${EXTRACTEDDIRNAME%-*}"
			RESULT=$(
				readonly ROEXTRACTEDDIRNAME="$EXTRACTEDDIRNAME"
				readonly ROVERBOSITY="'"$VERBOSITY"'"
				readonly ROALLPKGFIELDS=('"${ALLPKGFIELDS[@]}"')
				readonly ROVALIDOPTIONS=('"${VALIDOPTIONS[@]}"')
				readonly ROVALIDARCHES=('"${VALIDARCHES[@]}"')
				readonly ROVALIDILICENSES=('"${VALIDILICENSES[@]}"')
				readonly ROVALIDLICENSES=('"${VALIDLICENSES[@]}"')
				source "$PACKAGE" 2>/dev/null
				[[ $(expr index "$(declare -p)" $'"'\r'"') != 0 ]] && echo "Aborting: Found line feeds.  Remember, CRLF PKGBUILDs cannot be sourced by makepkg." && exit
				
				if [[ "$ROVERBOSITY" -ge 3 ]]; then
					ALLSETVARS=($(sed "/^_/d;s/=.*//" "$PACKAGE"))
					for SETVARIABLE in "${ALLSETVARS[@]}"
					do
						{ inarray false "$SETVARIABLE" "${ROALLPKGFIELDS[@]}" && ! [[ "$SETVARIABLE" =~ "-+" ]]; } || echo "[*] Unknown non-underscored variable $SETVARIABLE set."
					done
				fi

				REQUIREDFIELD=true
				ISSTRING=true
				NUMSUMS=0
				NUMSUMTYPES=0
				for PKGBUILDFIELD in "${ROALLPKGFIELDS[@]}"
				do
					$REQUIREDFIELD && [[ "$PKGBUILDFIELD" == "-" ]] && ISSTRING=false && continue
					$REQUIREDFIELD && [[ "$PKGBUILDFIELD" == "--" ]] && REQUIREDFIELD=false && ISSTRING=true && continue
					[[ "$PKGBUILDFIELD" == "---" ]] && ISSTRING=false && continue

					VARIABLETYPE=$(declare -p "$PKGBUILDFIELD" 2>/dev/null | cut -d " " -f 2)
					if [[ "$VARIABLETYPE" != "" ]]; then
						if $ISSTRING && [[ "$VARIABLETYPE" =~ ^[^Aa]+$ ]]; then
							$REQUIREDFIELD && [[ "${!PKGBUILDFIELD}" == "" ]] && echo "[*] $PKGBUILDFIELD is not set."
							validate_$PKGBUILDFIELD
						elif ! $ISSTRING && [[ "$VARIABLETYPE" == *[Aa]* ]]; then
							$REQUIREDFIELD && TMPVAR="$PKGBUILDFIELD""[@]" && [[ "${!TMPVAR}" == "" ]] && echo "[*] $PKGBUILDFIELD is not set."
							validate_$PKGBUILDFIELD
						else
							$ISSTRING && echo "[*] $PKGBUILDFIELD should be a string but was an array. Skipped." || echo "[*] $PKGBUILDFIELD should be an array but was a string.  Skipped."
						fi
					fi
				done

				{ [[ "$NUMSUMS" != "${#source[@]}" ]] || [[ "$NUMSUMTYPES" -gt 1 ]]; } && echo "[*] Contains confusing source checksums.  ($NUMSUMS checksums in $NUMSUMTYPES hash formats, ${#source[@]} sources.)"

				validate_archivefiles
				validate_disgustingstrings

				exit 0
			)
			[[ $? == 1 ]] && RESULT="Aborting: Could not load data, likely due to use of an associative array."
			
			[[ $RESULT != "" ]] && echo "$EXTRACTEDDIRNAME ($APPLICABLEARCHES)" && echo "$RESULT" && echo
		done
	'
	popd >/dev/null
}

VERBOSITY=0
while getopts "v" OPTION; do
	case "$OPTION" in
		v)
			VERBOSITY=$((VERBOSITY+1))
			;;
	esac	
done

# prep
# coalesce
# urlcheck
# coalesce
# urlcheck
# coalesce
genreport